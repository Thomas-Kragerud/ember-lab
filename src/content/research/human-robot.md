---
title: "Human-Robot Collaboration"
slug: "human-robot"
order: 1
summary: "Developing robots that can work alongside humans in shared workspaces, interpreting human gestures and intentions."
homepage_image: "/images/research/human-robot.webp"
featured: true
images:
  - url: "/images/research/human-robot.webp"
    alt: "Robot collaborating with human in a shared workspace"
    caption: "Our robots learn to interpret human gestures and intentions"
  - url: "/images/research/human-robot.webp"
    alt: "Robot assisting in manufacturing"
    caption: "Collaborative robots in manufacturing environments"
key_papers:
  - pathways
  - dile_mpc
---

Our research in Human-Robot Collaboration focuses on enabling robots to work effectively alongside humans in shared spaces. This requires robots to understand human intentions, communicate their own plans, and adapt to changing environments in real-time.

## Key Research Directions
 
- **Intention recognition**: Developing models that can infer human goals from partial observations and natural movements
- **Adaptive collaboration**: Creating frameworks for robots to adjust their behavior based on human preferences and work styles
- **Safety-aware planning**: Designing motion planning algorithms that prioritize human safety while maintaining task efficiency
- **Intuitive interfaces**: Building communication channels that allow for seamless human-robot interaction without specialized training

Through this work, we aim to create robotic systems that can be deployed in environments ranging from manufacturing floors to healthcare settings, augmenting human capabilities rather than replacing them.

Our latest projects involve using multimodal learning to integrate visual, tactile, and linguistic cues for more natural human-robot interaction. We're particularly excited about our recent advances in gesture-based teaching, which allows non-experts to quickly program robots for new tasks.